%%{init: {'theme': 'base', 'themeVariables': {'primaryColor': '#e8f4f8', 'primaryTextColor': '#1a1a2e', 'primaryBorderColor': '#16213e', 'lineColor': '#0f3460', 'secondaryColor': '#f0e6d3', 'tertiaryColor': '#fce4ec', 'noteBkgColor': '#fff9c4', 'noteTextColor': '#333', 'noteBorderColor': '#f9a825'}}}%%

flowchart TD

    %% ===== STAGE 1: ACQUIRE =====
    subgraph S1["<b>STAGE 1: ACQUIRE</b>"]
        direction TB
        A1["ğŸ“š Physical books<br/><i>Lyceum Libraries:<br/>KeÅ¾marok, PreÅ¡ov, Bratislava</i>"]
        A2["ğŸ›ï¸ DIKDA Repository<br/><i>Slovak National Library<br/>~3,000â€“4,000 pp. StÃ¶ckel digitised</i>"]
        A3["ğŸ–¼ï¸ Master Images<br/><b>TIFF / JPEG2000 / PNG</b>"]
        A1 -. "already digitised<br/>by SNK" .-> A2
        A2 --> A3
    end

    %% ===== STAGE 2: PARSE =====
    subgraph S2["<b>STAGE 2: PARSE</b>"]
        direction TB
        B1["âš™ï¸ OCR Processing<br/><b>ocr_processor.py --format both</b><br/><i>Tesseract + Poppler (PDF/TIFF/JPG/PNG)<br/>Also: ABBYY FineReader (SNK standard)<br/>Transkribus/Kraken for Fraktur</i>"]
        B2["ğŸ“„ ALTO XML + Clean Plaintext<br/><i>Dual output in one step<br/>data/alto/*.xml + data/cleaned/*.txt</i>"]
        B3["ğŸ“Š Confidence Extraction<br/><b>âœ… extract_alto.py</b><br/><i>Parses ALTO XML (Tesseract or ABBYY)<br/>â†’ plaintext + per-word confidence CSV</i>"]
        B4["ğŸ“ Normalized Plaintext<br/><b>âœ… normalize_text.py</b><br/><i>Orthographic normalization +<br/>abbreviation expansion (17 patterns)<br/>â†’ expansion_log for Layer 2 provenance</i>"]
        B1 --> B2
        B2 --> B3
        B3 --> B4
    end

    %% ===== STAGE 3: FILTER =====
    subgraph S3["<b>STAGE 3: FILTER</b>"]
        direction TB
        C1["ğŸ“‹ Entity Type Schema<br/><b>7 types defined</b>"]
        C2["Biblical_citation<br/><i>Matt. 5,3â€“12</i>"]
        C3["Patristic_reference<br/><i>Aug. de civ. Dei XIV.28</i>"]
        C4["Confessional_reference<br/><i>CA Art. IV</i>"]
        C5["Hymnological Â· Cross_ref<br/>Glossed_term Â· Section_header"]
        C6["âœï¸ INCEpTION<br/><b>Manual annotation</b><br/><i>Training data creation<br/>Export: UIMA CAS XMI</i>"]
        C1 --- C2
        C1 --- C3
        C1 --- C4
        C1 --- C5
        C1 --> C6
    end

    %% ===== STAGE 4: MINE =====
    subgraph S4["<b>STAGE 4: MINE</b><br/><i>CIC_annotation Pipeline (adapted)</i>"]
        direction TB
        D0["ğŸ“¥ BIOES Input<br/><i>cas_to_bioes.py (adapted)<br/>Multi-type: BIB, PAT, REF, AN, ...</i>"]
        DL["<b>Layers 1â€“5</b> (each reads input ZIP independently)<br/><i>1. Rules Â· 2. Abbreviations Â· 3. Match<br/>4. CRF Â· 5. Structure<br/>Each writes to own output dir</i>"]
        D6["ğŸ”€ Merge + Post-process<br/><i>merge_annotations.py<br/>First-method-wins priority<br/>(L1 > L2 > L3 > L4 > L5)<br/>+ mark_source provenance</i>"]
        D0 --> DL --> D6
    end

    %% ===== STAGE 4b: EPISTEMOLOGICAL CLASSIFICATION =====
    subgraph S4b["<b>Epistemological Classification</b>"]
        direction TB
        E1["âœ… FACTUAL<br/><i>â‰¥2 methods agree (consensus)<br/>OR unambiguous pattern<br/>(biblical+verse â‰¥ 0.85,<br/>confessional â‰¥ 0.80)</i>"]
        E2["ğŸ” INTERPRETIVE<br/><i>Single method<br/>conf. 0.70â€“0.85</i>"]
        E3["ğŸ‘¤ DEFERRED<br/><i>Methods disagree on type<br/>conf. < 0.70<br/>or theological judgment</i>"]
    end

    %% ===== STAGE 5: REPRESENT =====
    subgraph S5["<b>STAGE 5: REPRESENT</b>"]
        direction TB
        F0["âœ… <b>build_corpus_json.py</b><br/><i>Pipeline output â†’ structured JSON<br/>with detection provenance +<br/>consensus tracking</i>"]
        F0B["âœ… <b>Corpus Browser</b><br/><i>docs/prototype/index.html<br/>Dashboard, search, filters,<br/>consensus visualization</i>"]
        F1["ğŸ“Š Citation Index<br/><i>Cross-reference database<br/>CSV / JSON</i>"]
        F2["ğŸ•¸ï¸ Network Graphs<br/><i>Co-citation analysis<br/>D3.js visualisation</i>"]
        F3["ğŸ§Š GNORM 3D Vis<br/><i>ariannapavone.com/gnorm/<br/>Input format TBD</i>"]
        F0 --> F0B
        F0B --- F1
        F0B --- F2
        F0B --- F3
    end

    %% ===== STAGE 6: REFINE =====
    subgraph S6["<b>STAGE 6: REFINE</b>"]
        direction TB
        G1["ğŸ” Filter by type<br/><i>Biblical vs. Patristic<br/>vs. Confessional</i>"]
        G2["ğŸ“ˆ Confidence filter<br/><i>FACTUAL only<br/>or include INTERPRETIVE</i>"]
        G3["ğŸ• Chronological<br/><i>Citation evolution<br/>across StÃ¶ckel's works</i>"]
    end

    %% ===== STAGE 7: INTERACT =====
    subgraph S7["<b>STAGE 7: INTERACT</b>"]
        direction TB
        H1["ğŸŒ Omeka S Platform<br/><i>Browse, search, explore<br/>IIIF image overlay</i>"]
        H2["ğŸ“¦ Export Formats<br/><i>CSV Â· TEI XML Â· Dublin Core<br/>MARC21 â†’ SNK/Kramerius 7</i>"]
        H3["ğŸ‘¥ End Users<br/><i>Reformation scholars<br/>Historical linguists<br/>Libraries Â· RESILIENCE</i>"]
        H1 --> H2 --> H3
    end

    %% ===== CONNECTIONS BETWEEN STAGES =====
    S1 -->|"TIFF / JPEG2000"| S2
    S2 -->|"normalized plaintext<br/>+ expansion_log"| S3
    S3 -->|"UIMA CAS XMI"| S4
    D6 --> S4b
    S4b -->|"annotated + classified"| S5
    S5 -->|"CSV / JSON"| S6
    S6 -->|"refined datasets"| S7

    %% ===== PROTOTYPE SHORTCUT =====
    S2 -. "current prototype path<br/>(rule-based detection<br/>in build_corpus_json.py)" .-> S5

    %% ===== INCEpTION ROUNDTRIP =====
    S4 -. "bioes_to_cas.py<br/>â†’ back to INCEpTION<br/>for expert review" .-> S3

    %% ===== STYLING =====
    style S1 fill:#e3f2fd,stroke:#1565c0,stroke-width:2px
    style S2 fill:#e8f5e9,stroke:#2e7d32,stroke-width:2px
    style S3 fill:#fff3e0,stroke:#e65100,stroke-width:2px
    style S4 fill:#fce4ec,stroke:#c62828,stroke-width:2px
    style S4b fill:#f3e5f5,stroke:#6a1b9a,stroke-width:2px
    style S5 fill:#e0f2f1,stroke:#00695c,stroke-width:2px
    style S6 fill:#f1f8e9,stroke:#558b2f,stroke-width:2px
    style S7 fill:#ede7f6,stroke:#4527a0,stroke-width:2px
