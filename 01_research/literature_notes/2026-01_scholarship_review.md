# Literature Review: Recent Scholarship on AI, Personalism, and Hermeneutics

**Date:** January 2026  
**Purpose:** Scholarly sources discovered via Scholar Gateway to enhance the philosophical documentation  
**Status:** Annotated bibliography with project applications

---

## Overview

This document compiles recent peer-reviewed scholarship (2018‚Äì2025) at the intersection of the project's three philosophical pillars:

1. **Personalist Philosophy & AI Ethics** ‚Äî How personalism informs ethical AI design
2. **Hermeneutics & Digital Methods** ‚Äî Integrating interpretation theory with computational approaches
3. **Epistemic Humility in AI** ‚Äî Communicating uncertainty and AI limitations
4. **AI in Religious Studies** ‚Äî Applications and challenges specific to theological research

---

## 1. Personalist Philosophy & AI Ethics

### 1.1 Mel√©, D. (2024). "What is the humanistic and ethical value of the 'logic of gift' in business relationships? A conceptual approach." *Business and Society Review*, 129(S1), 741-758.

**DOI:** https://doi.org/10.1111/basr.12361  
**Relevance:** üî¥ Essential  
**Open Access:** Yes

**Key Arguments:**

The article provides a rigorous contemporary synthesis of personalist philosophy's core tenets, drawing on Aquinas, Kant, Buber, Wojtyla, and Polo. Key personalist claims directly applicable to our framework:

- **Person as coexisting and relational being**: "The person does not exist alone but accompanied by other beings and open to relationship and interaction" (Polo, 2015).
- **Self-determination as personal quality**: Personalism highlights "the capacity of making free decisions regarding external aims and, consequently, developing one's own moral character."
- **I-Thou vs. I-It relations**: Drawing on Buber, the article contrasts relational encounter ("I-Thou") with utilitarian treatment ("I-It"). The person must be treated as "you," not as "it."
- **Donal love**: Leonardo Polo's concept of the person's fundamental capacity for "giving gratuitously and giving oneself."

**Project Application:**

This source provides contemporary philosophical vocabulary for articulating why AI must preserve researcher agency. The I-Thou/I-It distinction maps directly to our design principle: AI should approach dialogue rather than instrumentalism. The emphasis on self-determination grounds our human-centered tool-calling patterns‚Äîthe researcher must remain the "acting person" who decides.

**Key Quote for Working Paper:**
> "Man is not defined ultimately, or only, as the being capable of having (‚Ä¶) Man is a personal being because he is capable of giving." ‚Äî Polo (2012)

---

### 1.2 Gastmans, C., et al. (2024). "Christian anthropology-based contributions to the ethics of socially assistive robots in care for older adults." *Bioethics*, 38(9), 787-795.

**DOI:** https://doi.org/10.1111/bioe.13322  
**Relevance:** üü° Important  
**Open Access:** No

**Key Arguments:**

Identifies seven anthropological considerations grounded in biblical scriptures, Roman Catholic documents, and recent research for evaluating AI/robot ethics. Notable for integrating Gabriel Marcel's distinction between *corps-sujet* and *corps-objet*:

- Humans do not merely *have* a body; they *are* their body‚Äîan "incarnated spirit" bearing meanings.
- The "embodied and relational nature of human beings implies that they do not have a body; rather, they are their body."
- Human personhood is exercised "in mutual relationships of self-gift that are self-expressive and other-receiving."

**Project Application:**

Provides theological-anthropological grounding for why AI cannot replicate the embodied, situated nature of interpretation. Useful for Section 2.1 of the Epistemic Modesty Framework‚Äîstrengthens the claim that AI cannot stand in for the person-as-interpreter.

---

### 1.3 Donati, P. (2020). "A critical realist perspective on humanness as a meaningful re-entry of relational distinctions." *Journal for the Theory of Social Behaviour*, 51(1), 49-71.

**DOI:** https://doi.org/10.1111/jtsb.12252  
**Relevance:** üü° Important  
**Open Access:** No

**Key Arguments:**

Addresses how digital technologies challenge traditional humanism while arguing that the human "re-emerges as an intransitive essence endowed with an original, humble, relational dignity." Key insight:

- "Attributing meaning is a solely human activity, since symbolisation is not equivalent to the production of signs‚Äîcommon currency in the non-human world‚Äîbut indicates a meta-reality."
- Human dignity is "intransitive" because it is differential‚Äîthe human is "the origin of all the differential distinctions in terms of their meaning."

**Project Application:**

Directly supports the epistemic modesty framework's claim that meaning-attribution remains irreducibly human. AI can produce "signs" (pattern recognition outputs) but not "symbols" in the full human sense. This distinction strengthens the theoretical basis for the `[DEFERRED]` indicator.

---

### 1.4 van der Rijt, J., Coelho Mollo, D., & Vaassen, B. (2025). "AI Mimicry and Human Dignity: Chatbot Use as a Violation of Self-Respect." *Journal of Applied Philosophy*, 0(0).

**DOI:** https://doi.org/10.1111/japp.70037  
**Relevance:** üü° Important  
**Open Access:** Yes

**Key Arguments:**

Argues that chatbot interactions can offend human dignity because chatbots "mimic human linguistic behaviour but lack the moral and rational capacities essential for genuine interpersonal respect." Drawing on second-personal accounts of dignity:

- "Second-personal respect is premised on reciprocal recognition of second-personal moral authority."
- Since chatbots cannot reciprocate such recognition, treating them as if they could amounts to "subtle but significant violations of self-respect."
- Without reciprocity, "ascribing second-personal authority to an entity is a form of self-debasement."

**Project Application:**

Provides a *cautionary* perspective for our framework. While our project seeks to make AI interaction more "dialogical," this article warns against anthropomorphizing AI in ways that undermine human dignity. The design implication: AI should be *transparent about its non-personhood* while still being responsive and helpful. This reinforces why `[DEFERRED]` matters‚Äîit signals that the AI is not claiming interpretive authority it cannot possess.

---

### 1.5 Padela, A. I., et al. (2025). "Assisting, Replicating, or Autonomously Acting? An Ethical Framework for Integrating AI Tools and Technologies in Healthcare." *Bioethics*, 40(1), 52-60.

**DOI:** https://doi.org/10.1111/bioe.70019  
**Relevance:** üü¢ Helpful  
**Open Access:** No

**Key Arguments:**

Proposes a two-axis framework for evaluating AI in healthcare: (1) spectrum of patient engagement, (2) clinician's role. Central claim:

- "The central argument for AI in serving human ends is that it must promote human agency."
- AI should "affirm both bodily and psychological integrity‚Äîalso described as 'identity integrity.'"
- "AI should not be used to refashion human beings anew."

**Project Application:**

The healthcare framework has clear analogues to our religious studies context. The spectrum of AI engagement (assisting ‚Üí replicating ‚Üí acting autonomously) maps to our four levels of engagement. Technologies that "primarily assist" have "the least ethical challenges," while those that work "autonomously in therapeutic or decisional roles are the most controversial."

---

## 2. Hermeneutics & Digital Methods

### 2.1 Oberbichler, S., et al. (2021). "Integrated interdisciplinary workflows for research on historical newspapers: Perspectives from humanities scholars, computer scientists, and librarians." *Journal of the Association for Information Science and Technology*, 73(2), 225-239.

**DOI:** https://doi.org/10.1002/asi.24565  
**Relevance:** üî¥ Essential  
**Open Access:** Yes

**Key Arguments:**

Proposes an "integrated digital hermeneutics workflow" that combines computational methods with traditional hermeneutical practices. Following Droysen and Gadamer, identifies three research steps:

1. **Heuristics**: Elaborating research questions, finding/selecting source material
2. **(Source) Criticism**: Critically engaging with material‚Äîrelevancy, authenticity, appropriateness
3. **Interpretation**: Gaining knowledge by skillfully combining information and data

Key insight: "The integrated digital hermeneutics workflow... emphasizes the importance of iterative (qualitative) analytical steps over the data, in order to gradually gain deeper insights into it... It emphasizes critical reflections of both data and tools in the spirit of hermeneutics, which requires openness and transparency of the methods and tools."

**Project Application:**

This is perhaps the most directly relevant methodological source. The "integrated digital hermeneutics" framework can be adapted for our AI agent design:
- The agent should support all three steps, not just retrieval
- Critical reflection on tools and methods aligns with our epistemic modesty principle
- The emphasis on iterative engagement supports our narrative memory system (preserving the hermeneutical journey)

---

### 2.2 Andrushchenko, M., et al. (2021). "Using parsed and annotated corpora to analyze parliamentarians' talk in Finland." *Journal of the Association for Information Science and Technology*, 73(2), 288-302.

**DOI:** https://doi.org/10.1002/asi.24500  
**Relevance:** üü° Important  
**Open Access:** Yes

**Key Arguments:**

Demonstrates that "a digital humanities inquiry... cannot only rely on computational humanities modeling, but needs to accommodate a range of perspectives starting with simple searches, quantitative exploration, and ending with modeling." Key insight:

- "Even in complex modeling tasks... there was a need to revert back to simpler methods in order to facilitate contextual knowledge that supports interpretation of models."
- "The interpretative element is strong. Even if modeling is successful, the most crucial part of a study lies in the interpretation of the results and that cannot be performed without the contemporary humanities perspective."

**Project Application:**

Reinforces that computational methods are *necessary but not sufficient*. The human researcher must interpret model outputs‚ÄîAI cannot replace this interpretive role. This aligns with our multi-level engagement model: even at the highest level (Collaborative Reasoning), the researcher remains the interpreter.

---

### 2.3 Shaw, R. (2023). "Conceptual modeling as language design." *Journal of the Association for Information Science and Technology*, 76(2), 353-363.

**DOI:** https://doi.org/10.1002/asi.24739  
**Relevance:** üü¢ Helpful  
**Open Access:** No

**Key Arguments:**

Argues that conceptual modeling should be understood "not as a scientific process of discovery, but as a constructive process of language design." Quotes Carus & Ogilvie (2009):

> "Quantitative tests of the hermeneutic understanding do not then simply supersede that original understanding. The progress from qualitative to quantitative is not a one-way street... The quantitative cross-check is the beginning, rather, of an open-ended dialectical or mutual feedback process between the original hermeneutic understanding and quantitative data generated to test it."

**Project Application:**

Supports the framework's claim that computational analysis and hermeneutical understanding exist in "dialectical" relationship, not hierarchical replacement. The AI agent should facilitate this dialectic, not collapse it.

---

## 3. Epistemic Humility in AI Systems

### 3.1 Ha, S., Monadjemi, S., & Ottley, A. (2024). "Guided By AI: Navigating Trust, Bias, and Data Exploration in AI-Guided Visual Analytics." *Computer Graphics Forum*, 43(3).

**DOI:** https://doi.org/10.1111/cgf.15108  
**Relevance:** üü° Important  
**Open Access:** No

**Key Arguments:**

Empirical study of how AI transparency affects user trust and behavior. Key findings:

- "A common approach to promote transparency is showing uncertainties of the AI."
- "Prediction-specific confidence information could support trust calibration" (Zhang et al., 2020).
- "The users' trust in the AI teammate's outcomes is influenced by their awareness of the various kinds of uncertainty that exist or are generated in the system" (Sacha et al., 2016).
- However, "too much information about the AI could lead to worse performance or decision-making outcomes."

**Project Application:**

Provides empirical support for the epistemic indicator approach, but with caveats. Confidence displays support appropriate trust calibration, but must be balanced‚Äîindicator fatigue is a real risk. Our design should be "non-intrusive" and only deploy indicators "when genuinely informative."

---

### 3.2 Stokes, C., et al. (2024). "From Delays to Densities: Exploring Data Uncertainty through Speech, Text, and Visualization." *Computer Graphics Forum*, 43(3).

**DOI:** https://doi.org/10.1111/cgf.15100  
**Relevance:** üü¢ Helpful  
**Open Access:** No

**Key Arguments:**

Explores how different modalities (speech, text, visualization) communicate uncertainty:

- "Data uncertainty refers to the range of potential outcomes, variability within a dataset, or possible error in measurements or predictions."
- "While experts might understand statistical nuances like confidence intervals or p‚Äêvalues, a lay audience might misread these indicators and make incorrect conclusions."
- "Conveying data uncertainty also affects trust, at times enhancing it... However, uncertain data might also lead the audience to view the information as unreliable."

**Project Application:**

Informs the design of epistemic indicators. Text-based indicators (our `[FACTUAL]`, `[INTERPRETIVE]`, `[DEFERRED]`) should be calibrated for the target audience‚Äîscholarly researchers who can handle nuance but may not be technical experts. The key is clear, consistent vocabulary.

---

### 3.3 Naser, M. Z. (2025). "A Guide to Machine Learning Epistemic Ignorance, Hidden Paradoxes, and Other Tensions." *WIREs Data Mining and Knowledge Discovery*, 15(3).

**DOI:** https://doi.org/10.1002/widm.70038  
**Relevance:** üü° Important  
**Open Access:** Yes

**Key Arguments:**

Comprehensive catalogue of 175 "unconventional concepts" capturing paradoxes, tensions, and overlooked risks in ML practice. Proposes a "Paradox Detection and Remediation Framework" (PDRF). Key insight on epistemic uncertainty:

- Distinguishes "aleatoric" (inherent randomness) from "epistemic" (knowledge limits) uncertainty.
- Calls for "explicit representation of the limits of model knowledge."
- Argues for systems that "balance predictive power with epistemic transparency."

**Project Application:**

Technical vocabulary for discussing AI limitations. The aleatoric/epistemic distinction could refine our indicator framework: `[INTERPRETIVE]` often reflects epistemic uncertainty (what we don't know), while some factual claims may still carry aleatoric uncertainty (measurement variability). However, for practical purposes, the tripartite distinction may suffice.

---

## 4. AI Applications in Religious Studies

### 4.1 Reed, R. (2021). "The theology of GPT-2: Religion and artificial intelligence." *Religion Compass*, 15(11).

**DOI:** https://doi.org/10.1111/rec3.12422  
**Relevance:** üî¥ Essential  
**Open Access:** No

**Key Arguments:**

Foundational article connecting AI directly to religious studies. Three-fold task for religious studies in the AI age:

1. "Joining the clarion call to ensure that any deployment of artificial intelligence is done in such a way that it does not digitally reinscribe... prejudice and discrimination"
2. "Take advantage of an application of A.I. through interdisciplinary work that provides the avenue for new understandings of our data"
3. "Use our understanding of human constructions of superintelligent agents in the past to make sense of the ones that confront us"

On AI and religious texts: "There may be potential to discover unknown patterns in our textual data that we had not previously been aware of." Reed's team used ML models "to determine whether it could distinguish between authentic and deutero-Pauline texts" and found newer models "able to replicate the conclusions of scholarship almost exactly."

On bias: "What becomes apparent is that from GPT-2's perspective 'Sheilaism' (GPT-2ism?) is alive and well"‚ÄîAI text generation reflects the biases of its training data.

**Project Application:**

Directly relevant to our project rationale. Reed articulates both the promise (pattern discovery) and the peril (bias reinscription) of AI in religious studies. The article supports our claim that religious studies has specific stakes in AI design. The reference to "Sheilaism" reinforces why `[DEFERRED]` matters‚ÄîAI may blend theological traditions inappropriately.

---

### 4.2 Wahid, S. H. (2025). "When Robot Meets the God: Exploring the Relationship between Religion and AI." *Religious Studies Review*, 51(2), 483-488.

**DOI:** https://doi.org/10.1111/rsr.17910  
**Relevance:** üü° Important  
**Open Access:** No

**Key Arguments:**

Review article synthesizing recent scholarship on religion and AI. Key themes:

- Transhumanism and religious expectations of transcendence
- Apocalyptic discourses on AI as "digital savior" or "existential threat"
- AI ethics requiring collaboration across fields "including religious perspectives"
- How "algorithms can reproduce certain supremacies, thus demanding an 'ethics of liberation'"

Concludes: "AI must not only be designed with transparency and accountability but also with awareness of its spiritual and moral implications. The integration of theological wisdom into AI discourse can help cultivate a vision in which technology complements, rather than replaces, the ethical and communal values that have long defined human civilization."

**Project Application:**

Provides recent scholarly warrant for the project's intervention. The call for "theological wisdom" in AI design is precisely what our personalist-hermeneutical framework offers. The article positions our project within an emerging interdisciplinary conversation.

---

### 4.3 Caidi, N., et al. (2025). "Spiritual and religious information experiences: An Annual Review of Information Science and Technology (ARIST) paper." *Journal of the Association for Information Science and Technology*, 77(1), 40-61.

**DOI:** https://doi.org/10.1002/asi.24983  
**Relevance:** üü¢ Helpful  
**Open Access:** Yes

**Key Arguments:**

Comprehensive review of research on spiritual/religious information experiences. Notes "the advent of artificial intelligence (AI) and machine learning (ML) holds palpable yet unrecognized design and access implications" for religious communities. Cites the concept of "post-secular computing":

- Post-secular computing aims to "recenter the ethical sensibilities of... faith, religion, and spirituality (FRS) communities as a means of designing technologies and policies that favor the communities' coexistence, social welfare, and well-being."

**Project Application:**

Positions our project within the broader conversation about "post-secular computing." The framework we're developing is one response to the call not to "neglect the sacred" in AI research and practice.

---

## Synthesis: Implications for Project

### For the Epistemic Modesty Framework

1. **Strengthened philosophical grounding**: The personalist sources (Mel√©, Gastmans, Donati) provide contemporary scholarly vocabulary for articulating why AI must preserve human agency. The I-Thou/I-It distinction, the concept of "intransitive" human dignity, and the uniquely human capacity for "symbolisation" (vs. mere sign-production) all support the framework's core claims.

2. **Cautionary note on anthropomorphism**: van der Rijt et al. warn against AI designs that invite inappropriate attribution of personhood. Our indicators should clarify AI's epistemic limitations without pretending to a reciprocity it cannot offer.

3. **Empirical support for uncertainty communication**: Ha et al. and Stokes et al. provide evidence that showing AI uncertainty supports appropriate trust calibration‚Äîbut must be balanced to avoid indicator fatigue.

### For the Working Paper

1. **Digital hermeneutics integration**: Oberbichler et al.'s "integrated digital hermeneutics workflow" provides a methodological framework that our AI agent can support. The three-step structure (heuristics ‚Üí criticism ‚Üí interpretation) maps to our engagement levels.

2. **Religious studies stakes**: Reed and Wahid articulate why religious studies has specific concerns about AI design‚Äîbias reinscription, theological conflation, the need for human interpretive authority. These warrant our project's intervention.

3. **Interdisciplinary positioning**: Multiple sources call for integration of theological/humanistic perspectives in AI ethics. Our project responds to this call.

### For the Prototype Documentation

1. **Confidence calibration**: Technical sources suggest that prediction-specific confidence information supports trust calibration. The GNORM confidence ‚Üí epistemic indicator mapping is empirically grounded.

2. **Balancing transparency and usability**: Evidence suggests that more information is not always better. Indicators should be "non-intrusive" and deployed only when genuinely informative.

---

## Citation Format Notes

All citations follow Chicago Manual of Style, 17th edition (Author-Date for in-text, Notes-Bibliography for formal references).

---

*This literature review will be expanded as reading progresses during the fellowship.*
