# Designing Ethically-Grounded AI Agents for Religious Studies Research: A Comprehensive Research Synthesis

**Author:** Prof. Michal Valčo  
**Affiliation:** Evangelical Lutheran Theological Faculty, Comenius University in Bratislava, Slovakia  
**Fellowship context:** ITSERR Transnational Access Fellowship, University of Palermo (February 2026)  
**Draft status:** Section-by-section development in progress  
**Target venues:** *AI & Society* (theoretical framework) / *Digital Scholarship in the Humanities* (technical companion)

---

## 1. Introduction: The Theological Turn in Artificial Intelligence

For decades, the Digital Humanities operated primarily as a discipline of digitisation and retrieval. Scholars scanned manuscripts, built databases, tagged corpora, and made texts searchable — an immense labour that transformed access to primary sources but left the interpretive work essentially untouched. The humanist still read, still wrestled with meaning, still argued over translations and theological implications. The computer helped *find* things. It did not pretend to *understand* them.

That settlement is now breaking down. The advent of agentic AI — systems capable of autonomous reasoning, tool use, persistent memory, and multi-step workflow orchestration — has fundamentally altered the research landscape. We are no longer merely digitising texts; we are building systems that plan research strategies, summarise arguments, identify intertextual connections, and generate synthetic analyses across vast corpora. LangGraph, CrewAI, and AutoGen provide production-ready frameworks for orchestrating such agents. The Model Context Protocol, adopted by every major AI provider within months of its 2024 release, enables these agents to connect with scholarly databases, annotation tools, and institutional repositories in real time. The infrastructure exists. The question is no longer *whether* AI agents will enter humanities research, but *what kind* of agents — and on whose terms.

This transition is not merely technical. It is epistemological. When a scholar encounters a text — say, Luther's exposition of Romans 3:28, or a passage from Leonard Stöckel's *De oboedientia politica* — the encounter involves what Gadamer called a *Horizontverschmelzung*, a fusion of horizons: the horizon of the text (its historical, linguistic, and theological situatedness) meets the horizon of the interpreter (shaped by training, confession, existential concerns, and scholarly tradition). When an AI agent mediates this encounter, it introduces what we might call a *third horizon* — one constituted not by tradition or lived experience, but by statistical probability and training weights. The agent has a "training distribution." It does not have *tradition* in Gadamer's sense. It processes tokens. It does not *dwell* in a hermeneutical community.

The implications are substantial. Elrod (2024) has demonstrated empirically that large language models queried with Hebrew Bible texts privilege progressive and broadly Christian interpretive frames, losing hermeneutical nuance in the process. A system that presents the results of statistical inference with the confidence of scholarly judgment does not merely make errors — it performs a kind of epistemic violence against the text and the traditions that have carried it. An agent for theological research must be designed with explicit awareness of this danger: it must know the difference between retrieving a fact and interpreting a passage, and it must never confuse the two.

This synthesis maps the territory where such an agent could be built. Developed during an ITSERR Transnational Access Fellowship at the University of Palermo (February 2026), in direct collaboration with the GNORM project team, it covers 2020–2026 literature across five domains: (1) AI agent architectures that support interpretive humanities work, with particular attention to memory systems and orchestration frameworks; (2) computational approaches to religious and legal texts, from Latin NLP to patristic databases to the conspicuous underrepresentation of Protestant theological corpora; (3) the philosophy of AI and hermeneutics, tracing the genealogy from Capurro's digital hermeneutics through the techno-gnosticism critique to digital theology as a distinct disciplinary space; (4) human-centred AI design, where Christian personalist anthropology meets graduated autonomy taxonomies and the Model Context Protocol; and (5) European research infrastructure for religious studies, including the RESILIENCE and ITSERR projects and the fragmented but substantial digitisation landscape of Central and Eastern Europe. Across these five domains, the synthesis identifies 142 primary sources spanning peer-reviewed scholarship, technical documentation, and institutional grey literature.

The claim is not modest, but it is precise. Five distinct literature gaps converge at a point that, taken together, defines a genuinely novel contribution space. No agentic system for theological research exists — current tools are simple chatbots or search interfaces, not systems with planning, memory, and calibrated confidence. Personalist anthropology has never been translated into AI architecture — the Rome Call for AI Ethics and Catholic Social Teaching provide principles, but no one has shown how relational ontology, narrative identity, or subsidiarity map to specific design decisions in an agent framework. Protestant theological corpora are computationally underserved — the Reformation is studied through social networks and print culture, not through NLP analysis of doctrinal texts. Epistemic modesty for interpretive domains is untheorised — all existing confidence calibration targets factual correctness, not the spectrum from historical fact to scholarly consensus to confessional interpretation. And ITSERR's emerging tools — CRITERION, GNORM, DaMSym, YASMINE — await agentic orchestration, having been built as standalone capabilities that could be unified through an integrated agent workflow.

The infrastructure exists. What is missing is the bridge.

---

## 2. AI Agent Architectures for Interpretive Humanities Work

### 2.1 Computational Hermeneutics as an Emerging Paradigm

The most significant theoretical development for situating AI agents within humanities research is the emergence of *computational hermeneutics* as a framework for evaluating generative AI systems in cultural and interpretive contexts. Kommers, Ahnert, Antoniak, and thirty-four additional co-authors from major digital humanities centres, writing from the Alan Turing Institute in 2025, propose that generative AI systems are fundamentally "context machines" that must address three interpretive challenges: *situatedness* (meaning emerges in context, not in isolation), *plurality* (multiple valid interpretations coexist for any text of complexity), and *ambiguity* (interpretations naturally conflict, and the conflict is itself productive). Their three evaluation principles — that benchmarks should be iterative, should include people, and should measure cultural context — translate directly into design requirements for any agent intended to assist theological research. This is not a niche concern. The leading computational humanities research institution in the Anglophone world has identified interpretive evaluation as the central challenge for generative AI in cultural domains.

The intellectual genealogy runs deeper than this 2025 synthesis. Mohr, Wagner-Pacifici, and Breiger defined computational hermeneutics as early as 2015 as the use of all available text analysis tools in pursuit of a theory of reading — a formulation that already anticipated the integration of machine learning into interpretive workflows. More recently, Piotrowski (2026) has reconceptualised interpretation itself as the construction of explicit, formalisable models, arguing that computational hermeneutics demands structured representations of interpretive processes rather than mere automation of textual analysis. This is a critical distinction: the point is not to automate hermeneutics but to *model* it — to make interpretive reasoning explicit enough that its assumptions can be examined, contested, and refined. Henrickson and Meroño-Peñuela (2023) take the practical step of introducing "hermeneuticity" as a measurable quality of AI outputs, demonstrating that prompt engineering strategies can increase it. If hermeneuticity can be measured, it can be designed for.

Directly relevant to the question of theological bias, Elrod's 2024 study queries five large language models (GPT-4 Turbo, Claude 2, Llama 2, Zephyr 7B, PaLM 2) with passages from the Hebrew Bible and demonstrates that these systems consistently privilege progressive and broadly Christian interpretive frames, systematically losing hermeneutical nuance. Meanwhile, work in *EPJ Data Science* (2025) presents a hybrid human-LLM workflow for qualitative coding that explicitly preserves what the authors call "hermeneutic value" while scaling analysis — demonstrating that chain-of-thought prompting and iterative code refinement can maintain interpretive rigour when the workflow is designed with such rigour in mind. These are not abstract concerns. They are measured empirical findings. An agent for theological research must be designed with awareness of specific directional biases — not merely the possibility of error, but the *kind* of error, the systematic direction in which the system tends to distort.

### 2.2 Comparative Analysis of Agent Orchestration Frameworks

Among current multi-agent orchestration frameworks, three have reached sufficient maturity to warrant serious consideration for a theological research agent prototype. Each embodies a different metaphor for intelligence, and each carries different implications for the kind of interpretive work the system can support.

**LangGraph** (LangChain, Inc.) models agent workflows as directed graphs — nodes representing processing steps and edges representing transitions between them. This architecture is a natural fit for representing the hermeneutical circle, where understanding of parts informs understanding of the whole and understanding of the whole reshapes interpretation of the parts. The graph is traversed iteratively, not linearly. LangGraph provides built-in statefulness, human-in-the-loop checkpoints at arbitrary nodes, both short-term and long-term memory, and modular tool integration via the Model Context Protocol. The "Open Deep Research" agent demonstrates a supervisor-researcher multi-agent architecture with plan-and-execute workflows — a pattern directly adaptable to theological research, where one might want a planning agent to decompose a complex exegetical question into retrievable sub-tasks (identify the textual tradition, locate relevant patristic commentary, check confessional positions, synthesise) before a research agent executes each step under scholarly oversight.

The State object in LangGraph deserves particular attention. It is not merely a collection of variables passed between nodes; it is the *locus* of the hermeneutical act. When the agent processes a passage and updates its state with a new interpretive finding — say, identifying that Stöckel's citation of Augustine's *De civitate Dei* XIV.28 echoes a specific argumentative pattern from the *Confessio Augustana* — that finding persists in the state, available to all subsequent nodes. The state accumulates the evolving interpretation. In religious studies, this matters because a hallucinated citation is not merely a software bug; it is a falsification of tradition. The graph's auditability — every node visit, every state mutation, every human checkpoint — provides the transparency that interpretive scholarship demands.

**CrewAI** offers a complementary role-based metaphor: agents are assigned roles, goals, and backstories, then collaborate on tasks. The roles map naturally onto a theological research workflow — one might configure a "Philologist Agent" tasked with textual analysis, a "Systematic Theologian Agent" responsible for doctrinal coherence checking, a "Historical Contextualiser" providing socio-political framing, and a "Cross-Reference Specialist" tracing intertextual networks. Somanunnithan's 2025 demonstration of a three-agent crew (search, summariser, fact-checker) confirms the practical viability of modular multi-agent design, showing that such architectures prove "more transparent and maintainable than a single all-in-one model." The role metaphor is accessible and pedagogically useful. But it carries a warning: the anthropomorphic framing risks obscuring the fact that these "agents" have no understanding of theology, no formation in a confessional tradition, no capacity for the *Verstehen* that theological interpretation requires. If multiple agents reinforce each other's outputs without external grounding, the result may be a sophisticated form of groupthink — hallucinations amplified by apparent consensus.

**Microsoft AutoGen** excels at open-ended, conversation-driven collaboration between agents, which makes it suitable for modelling scholarly debate. One could, in principle, program a "Thomist Agent" and a "Scotist Agent" to debate a contested theological question — a kind of digital *disputatio* that mirrors the scholastic method. The conversational paradigm permits emergent positions and unexpected syntheses. Yet it also introduces the risk of context drift: over extended exchanges, agents may wander into irrelevant theological speculation, producing outputs that feel profound but lack grounding. AutoGen's UserProxyAgent, which represents the human researcher in the conversation, provides a mechanism for periodic reality checks, though the burden of monitoring falls entirely on the scholar.

The framework comparison yields a clear recommendation. For a theological research agent requiring auditability, interpretive control, and integration with existing scholarly infrastructure, LangGraph's graph-based architecture is the strongest candidate. Its state management naturally models the accumulative character of hermeneutical understanding; its human-in-the-loop checkpoints respect the scholar's interpretive authority; and its native support for the Model Context Protocol enables connection to precisely the kind of domain-specific tools (GNORM, IxTheo, Sefaria) that ground agent outputs in authoritative sources rather than open-web inference.

### 2.3 Narrative Memory: Beyond Factual Recall

A religious studies researcher may spend years on a single corpus. Interpretive insights accumulate slowly — a connection between two passages noticed in March reshapes the reading of a third passage encountered in November. Theological understanding is not a database lookup; it is the cultivation of what Newman called an *illative sense*, a capacity for judgment that develops through sustained, patient engagement with texts and traditions. Early AI implementations suffered from what might be called catastrophic forgetting: each conversation began from zero, with no trace of prior interactions. For a researcher who has spent three sessions building toward a nuanced reading of Stöckel's use of Melanchthon, starting over is not merely inconvenient — it is destructive of the very interpretive continuity that constitutes scholarly work.

Current memory architectures for AI agents have matured rapidly, though they remain oriented toward factual recall rather than interpretive continuity. **MemGPT** (Packer et al., 2023), now the commercial Letta framework, introduces an operating-system-inspired hierarchy: *core memory* (maintained in-context, analogous to RAM) stores the most essential ongoing information; *archival memory* (a vector database, analogous to disk) preserves the full record of past interactions and consulted materials; and *recall memory* captures complete conversation histories for retrieval. The agent self-manages memory through function calls, deciding what to promote from archival to core memory as relevance shifts. For a theological agent, the mapping is suggestive: core memory could store the scholar's evolving interpretive framework — the working hypotheses, the key disputed questions, the confessional commitments that shape reading; archival memory maintains the consulted corpus and prior analyses; recall memory preserves the trail of inquiry.

**A-MEM** (Xu et al., 2025) introduces something more evocative: a Zettelkasten-inspired system where memories are interconnected "notes" with keywords, tags, and embeddings, linked through LLM-driven semantic analysis. The Zettelkasten — Luhmann's famous slip-box method — is not merely a storage system; it is a method for *thinking*, for building networks of interconnected insights that generate new ideas through unexpected juxtaposition. For theological research, where the connections between a patristic commentary, a Reformation confession, and a modern systematic treatment may be precisely what constitutes a scholarly contribution, A-MEM's architecture is directly relevant. It is superior to MemGPT for open-ended tasks because its linking mechanism mirrors how interpretive scholarship actually works — not through hierarchical filing but through lateral association and cumulative cross-reference.

**Zep** (Rasmussen et al., 2025) adds a temporal dimension through knowledge graphs that track how entities and relationships evolve over time. For tracking *Wirkungsgeschichte* — the reception history of theological concepts and texts across centuries — temporal knowledge graphs offer a natural computational substrate. How has the interpretation of Romans 3:28 shifted from Augustine through Luther through Barth? Zep's architecture could, in principle, model such trajectories.

Yet none of these systems addresses what might be called *narrative memory* — the capacity to maintain a coherent interpretive narrative across sessions, tracking not just facts but evolving understanding, interpretive commitments, and unresolved tensions. A theological research agent would need memory that captures the scholar's hermeneutical framework (not merely their search history), records how specific texts have been analysed (not merely that they were accessed), notes which traditions have been consulted (and which have been deliberately excluded), and maintains a register of open questions — the productive uncertainties that drive continued inquiry. This kind of memory is architecturally novel. No existing system implements it. A practical approximation might involve what has been called a "rolling summary" — a structured narrative document, updated after every interaction, that captures the current state of the research project in the scholar's own interpretive terms rather than in the system's internal representation. The agent generates it; the scholar corrects it. Over time, it becomes the shared memory of the research relationship.

### 2.4 The Critical Gap

No published work applies multi-agent orchestration frameworks to theological or religious studies research. The gap is comprehensive. Existing applications of LangGraph, CrewAI, and AutoGen target software engineering, finance, marketing, and general-purpose research. The CUNY Graduate Center launched the first known dedicated digital humanities graduate course on agentic AI in Spring 2025, signalling the field's emerging awareness. Two early exceptions push against the boundary: the University of Reading prototype (Alsayed, 2024) applies LangChain with fine-tuned LLMs to linguistic corpus annotation with iterative human review, and multi-agent architectures have been considered (though not yet published in peer-reviewed form) for multimodal historical data analysis. But peer-reviewed literature on applying agent frameworks specifically to humanities research — let alone theological research — remains essentially empty.

This is the first of five convergent gaps. It is also, in some respects, the most straightforward to address: the frameworks exist, the tools are mature, and what is required is not a technical breakthrough but a domain-specific application guided by appropriate philosophical commitments. The difficulty lies not in the engineering but in the design — in knowing what a theological research agent should *refuse* to do as clearly as what it should accomplish.

---

## 3. Epistemic Modesty and Calibrated Confidence

### 3.1 Why Epistemic Modesty Requires Its Own Architecture

Current AI evaluation metrics reward confidence. Systems are penalised for hedging, rewarded for decisive answers, optimised to produce fluent, authoritative-sounding prose regardless of whether the underlying claim is a verified historical fact or a contested theological interpretation. The result is what one might call an epidemic of penalised uncertainty — systems trained to never say "I'm not sure," even when uncertainty is the only epistemically honest response.

For theological research, this is not a minor calibration problem. It is a fundamental design flaw. If the person is constituted by narrative and relational encounter — as personalist anthropology insists — then an AI that feigns certainty distorts the relational encounter between scholar and text. The agent's confident prose becomes a screen between the researcher and the productive uncertainty that drives genuine inquiry. A hermeneutical tradition stretching from Augustine's *De doctrina Christiana* through Gadamer's *Truth and Method* has insisted that *not knowing* — the awareness of one's own prejudices, the willingness to be surprised by the text — is not a deficiency but a precondition of understanding. An ethically grounded agent must be designed to confront what might be called its shadow: its hallucinations and biases, its systematic tendency to present statistical inference as interpretive insight. It should not mask uncertainty with confident prose. It should make uncertainty visible.

Practical implementations of this principle are beginning to emerge. One approach involves a secondary "critic" agent that evaluates the primary agent's outputs, toning down unwarranted certainty and flagging claims that exceed the epistemic warrant of the underlying sources. Jenkins et al. (2025) introduce the concept of "epistemic friction" — the productive resistance that qualitative researchers encounter when their interpretive frameworks meet recalcitrant data. An agent designed for theological research should preserve, even cultivate, such friction rather than smoothing it away.

The technical landscape for uncertainty estimation in LLMs is now substantial, though almost entirely oriented toward factual domains. Wen et al. (2025), writing in *Transactions of the Association for Computational Linguistics*, provide the definitive survey on LLM abstention — the refusal to answer when uncertain — examining query characteristics, model capabilities, and alignment with human values. Kuhn, Gal, and Farquhar (2023) introduce *semantic entropy* for uncertainty estimation that accounts for linguistic invariance: the same meaning can be expressed in many ways, and genuine uncertainty should be distinguished from mere paraphrastic variation. This work, extended to hallucination detection in *Nature* (Farquhar et al., 2024), provides the most rigorous available method for identifying when an LLM is generating content untethered from its training data. For factual claims — "Paul wrote Romans around 57 CE" — semantic entropy offers a principled confidence measure.

But here is precisely the gap. All existing calibration work targets factual question-answering. The entire apparatus assumes a single dimension: correct versus incorrect, confident versus uncertain. Theological research operates on a fundamentally different epistemic terrain — one where multiple valid answers coexist by design, where "correct" is often meaningless, and where the system's task is not to resolve uncertainty but to map it.

### 3.2 A Four-Tier Epistemic Classification

What is needed is not better calibration on a single dimension but a multi-dimensional classification framework that distinguishes qualitatively different *kinds* of knowledge claims. We propose four tiers:

**Tier 1 — Factual/Historical:** Claims that are empirically verifiable and have determinate truth values. "Paul wrote Romans around 57 CE." "The Diet of Augsburg took place in 1530." "Leonard Stöckel studied at Wittenberg from 1530 to 1534." At this tier, the agent can present claims with standard confidence measures, cite sources, and flag disagreements among historians where they exist. Semantic entropy methods apply directly.

**Tier 2 — Scholarly Consensus:** Claims where a dominant scholarly position exists but acknowledged disagreement persists. "Most scholars date Mark as the earliest Gospel." "The *sola fide* formulation is generally attributed to Luther's reading of Romans, though its precise genealogy is debated." At this tier, the agent should present the consensus position with "according to" framing, explicitly flag the existence and nature of dissent, and never present a majority view as settled fact.

**Tier 3 — Interpretive/Confessional:** Claims where multiple valid readings coexist within recognised hermeneutical or confessional traditions. "This passage has been read as affirming double predestination (Reformed tradition), as emphasising the universality of grace (Lutheran tradition), and as compatible with libertarian free will (Arminian tradition)." At this tier, the agent must present multiple readings without selecting one. It maps the interpretive landscape. It never adjudicates.

**Tier 4 — Matters of Faith and Doctrine:** Questions where the system must defer entirely to human judgment. "What does this text mean for the Christian life?" "Is this doctrine true?" "How should a congregation respond to this teaching?" At this tier, the agent refuses to generate an answer. It may offer to retrieve relevant authorities — confessional documents, magisterial statements, theological commentaries — but the act of interpretation, application, and commitment belongs to the human person. This is the tier where the *inviolable dignity* of the person as interpreter is architecturally enforced.

Each tier maps to specific agent behaviours. The graduated response — from confident presentation through hedged framing through multi-perspective mapping through outright deferral — constitutes a machine-readable epistemic modesty that has no precedent in the current literature. All existing confidence calibration operates within Tier 1. Tiers 2 through 4 are uncharted.

### 3.3 Implementation Pathways

The prototype under development implements a belt-and-suspenders approach: the system prompt instructs the LLM to add epistemic tier tags inline (a lightweight first pass), while a dedicated classifier validates and adds missing tags based on sentence-level analysis. The classifier pipeline runs through a sequence: sentence classification based on linguistic markers, citation density checking, theological term detection, confidence scoring, and fallback rules. The approach is deliberately redundant — prompt-level guidance catches most cases; the classifier catches what the prompt misses.

Integration with the GNORM pipeline provides a second, independent confidence signal. The CIC_annotation system's `mark_source` mechanism tracks which pipeline layer produced each annotation (rule-based, abbreviation dictionary, trie matching, statistical gap prediction, or CRF model). When multiple layers agree on an annotation — say, both the rule-based detector and the CRF identify a biblical citation — confidence is high (Tier 1, FACTUAL). When only the CRF fires, with marginal probability between 0.70 and 0.85, the annotation is flagged for expert review (Tier 2, INTERPRETIVE). When methods disagree or confidence falls below 0.70, the annotation is deferred to a human annotator (DEFERRED). This dual-path approach — method consensus across pipeline layers *combined with* CRF marginal probabilities within the ML layer — is more robust than either mechanism alone, and represents a methodological extension beyond the original CIC_annotation design.

The LLM verification step — where semantic entropy methods would be integrated for ambiguous cases falling between tiers — remains to be implemented. It represents the most technically ambitious component of the epistemic modesty architecture and requires careful calibration against theological domain experts' judgments rather than generic factual benchmarks.

---

